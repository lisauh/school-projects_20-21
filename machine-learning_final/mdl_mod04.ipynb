{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804f2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bbb2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad92408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "90241649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8c0501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.1\n"
     ]
    }
   ],
   "source": [
    "# making sure it's 3.9\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c720e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on previous testing, decided to use:\n",
    "## tfidf\n",
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d45f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data files\n",
    "\n",
    "# has clean review text\n",
    "dataset = pd.read_json(\"dramainfo_revclean.json\")\n",
    "\n",
    "# tfidf\n",
    "tfidf_rev = np.load(\"tfidfvec.npy\")\n",
    "tfidf_vocab = np.load(\"tfidfvocab.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b8580f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df of the tfidf features\n",
    "tfidf_df = pd.DataFrame(tfidf_rev, columns=tfidf_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "8abc5b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romance', 'sitcom_comedy', 'comedy', 'war_historical', 'political_drama', 'thriller', 'friendship', 'melodrama_romance', 'drama', 'action', 'historical', 'youth_school', 'fantasy_supernatural_horror', 'mystery', 'life', 'family']\n"
     ]
    }
   ],
   "source": [
    "# names of all genre columns\n",
    "bat_targets = list(dataset.iloc[:,-17:-1].columns)\n",
    "print(bat_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "39ad4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_nearest(x, a):\n",
    "    return np.ceil(x/a)*a\n",
    "\n",
    "# return ratios for over and undersampling\n",
    "# oversample strat between 0.4,0.6\n",
    "# undersample strat 0.8 for a ~10 percent pt diff\n",
    "def over_under_strat(minority,majority):\n",
    "    # min and max ratios for oversampling\n",
    "    minr, maxr = (0.4,0.6)\n",
    "    \n",
    "    # rounded up to nearest 0.05\n",
    "    # keep at 2 digit decimal\n",
    "    orig_ratio = np.round(round_nearest(minority/majority,0.05),2)\n",
    "    \n",
    "    if (orig_ratio >= minr) and (orig_ratio <= maxr):\n",
    "        minr = orig_ratio\n",
    "    elif orig_ratio < minr:\n",
    "        pass\n",
    "    else: return None\n",
    "    \n",
    "            \n",
    "    # get the num points for 0.05 intervals\n",
    "    pnum = int(np.round((maxr-minr)*10*2+1))\n",
    "\n",
    "    overs = np.linspace(minr,maxr,pnum)\n",
    "    \n",
    "    # overstrat, understrat\n",
    "    # 0.8 for under will result in\n",
    "    # ~10 percentage point difference\n",
    "    return [(num, 0.8) for num in overs]\n",
    "\n",
    "# if ratio is <0.4, do oversample w strat 0.5\n",
    "# else only downsample\n",
    "def single_strat(minority,majority):\n",
    "    minr, maxr = (0.4,0.6)\n",
    "    \n",
    "    orig_ratio = minority/majority\n",
    "    \n",
    "    if orig_ratio >= minr and orig_ratio <= maxr:\n",
    "        return (None,0.8)\n",
    "    elif orig_ratio > maxr:\n",
    "        return (None,0.8)\n",
    "    else: return (0.5,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "6971e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def samp_strats(dataset=dataset, bat_targets=bat_targets):\n",
    "    # dict[genre] = (over strat, under strat)\n",
    "    samp_dict = dict()\n",
    "\n",
    "    for gen in bat_targets:\n",
    "        counts = Counter(dataset[gen])   \n",
    "        is_frac = counts[1]/(counts[0]+counts[1])\n",
    "\n",
    "        if is_frac >= 0.45 and is_frac <= 0.55:\n",
    "            samp_dict[gen]= (None,None)\n",
    "\n",
    "        else:\n",
    "            samp_dict[gen] = single_strat(min(counts[0],counts[1]),\n",
    "                                          max(counts[0],counts[1]))\n",
    "            #samp_dict[gen]=over_under_strat(min(counts[0],counts[1],\n",
    "            #                                max(counts[0],counts[1]))\n",
    "\n",
    "    return samp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "08f48d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'romance': (None, 0.8),\n",
       " 'sitcom_comedy': (None, 0.8),\n",
       " 'comedy': (None, 0.8),\n",
       " 'war_historical': (0.5, 0.8),\n",
       " 'political_drama': (None, None),\n",
       " 'thriller': (0.5, 0.8),\n",
       " 'friendship': (0.5, 0.8),\n",
       " 'melodrama_romance': (None, 0.8),\n",
       " 'drama': (None, None),\n",
       " 'action': (0.5, 0.8),\n",
       " 'historical': (0.5, 0.8),\n",
       " 'youth_school': (0.5, 0.8),\n",
       " 'fantasy_supernatural_horror': (0.5, 0.8),\n",
       " 'mystery': (0.5, 0.8),\n",
       " 'life': (0.5, 0.8),\n",
       " 'family': (0.5, 0.8)}"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_dict = samp_strats()\n",
    "samp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "dabad82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = bat_targets[0]\n",
    "\n",
    "ov_strat,un_strat = samp_dict[gen]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_rev,\n",
    "                                                    dataset[gen],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=18)\n",
    "\n",
    "# resampling\n",
    "if ov_strat != None and un_strat != None:\n",
    "    over = RandomOverSampler(sampling_strategy=ov_strat)\n",
    "    under = RandomUnderSampler(sampling_strategy=un_strat)\n",
    "    X_train,y_train = over.fit_resample(X_train,y_train)\n",
    "    X_train,y_train = under.fit_resample(X_train,y_train)\n",
    "elif ov_strat == None and un_strat != None:\n",
    "    under = RandomUnderSampler(sampling_strategy=un_strat)\n",
    "    X_train,y_train = under.fit_resample(X_train,y_train)\n",
    "else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "67d86470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline, grid search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "dd07b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"logreg\", LogisticRegression())])\n",
    "\n",
    "params_grid = [{\"logreg__penalty\": [\"l1\"],\n",
    "                \"logreg__C\": np.logspace(-2, 2, 5),\n",
    "                \"logreg__solver\": [\"lbfgs\"]\n",
    "               },\n",
    "               {\"logreg__penalty\": [\"l1\",\"l2\"],\n",
    "                \"logreg__C\": np.logspace(-2, 2, 5),\n",
    "                \"logreg__solver\": [\"saga\"],\n",
    "                \"logreg__random_state\": [1]\n",
    "               }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "f1bb59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model_selection.GridSearchCV(pipeline, param_grid=params_grid,\n",
    "                                   cv=5, verbose=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2c946893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.55546258\n",
      " 0.55546258 0.69694569 0.71746972 0.80116313 0.82376692 0.82041964\n",
      " 0.83088164 0.82502741 0.82544319]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('logreg', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'logreg__C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                          'logreg__penalty': ['l1'],\n",
       "                          'logreg__solver': ['lbfgs']},\n",
       "                         {'logreg__C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                          'logreg__penalty': ['l1', 'l2'],\n",
       "                          'logreg__random_state': [1],\n",
       "                          'logreg__solver': ['saga']}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/15] START logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 1/5; 1/15] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   3.2s\n",
      "[CV 5/5; 3/15] START logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 5/5; 3/15] END logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 3/5; 5/15] START logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs..\n",
      "[CV 3/5; 5/15] END logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.3s\n",
      "[CV 1/5; 7/15] START logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 7/15] END logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.554 total time=  31.7s\n",
      "[CV 4/5; 8/15] START logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 8/15] END logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.732 total time=  20.5s\n",
      "[CV 2/5; 10/15] START logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 10/15] END logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.803 total time= 2.4min\n",
      "[CV 2/5; 13/15] START logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 13/15] END logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.860 total time= 1.0min\n",
      "[CV 1/5; 14/15] START logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 14/15] END logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.814 total time= 2.8min\n",
      "[CV 4/5; 15/15] START logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 15/15] END logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.822 total time= 1.1min\n",
      "[CV 3/5; 1/15] START logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 3/5; 1/15] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   3.1s\n",
      "[CV 3/5; 3/15] START logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 3/5; 3/15] END logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 4/5; 4/15] START logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 4/5; 4/15] END logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.3s\n",
      "[CV 2/5; 6/15] START logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 6/15] END logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.554 total time=  11.7s\n",
      "[CV 3/5; 8/15] START logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 8/15] END logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.667 total time=  24.2s\n",
      "[CV 4/5; 9/15] START logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 9/15] END logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.720 total time=  26.3s\n",
      "[CV 2/5; 11/15] START logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 11/15] END logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.845 total time=  28.0s\n",
      "[CV 1/5; 12/15] START logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 12/15] END logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.812 total time= 2.5min\n",
      "[CV 4/5; 13/15] START logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 13/15] END logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.841 total time= 1.1min\n",
      "[CV 5/5; 14/15] START logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 14/15] END logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.816 total time= 2.6min\n",
      "[CV 1/5; 2/15] START logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 1/5; 2/15] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   3.2s\n",
      "[CV 1/5; 4/15] START logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 1/5; 4/15] END logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 4/5; 5/15] START logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs..\n",
      "[CV 4/5; 5/15] END logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 2/5; 7/15] START logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 7/15] END logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.554 total time=  32.0s\n",
      "[CV 5/5; 8/15] START logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 8/15] END logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.700 total time=  26.4s\n",
      "[CV 3/5; 10/15] START logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 10/15] END logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.776 total time= 2.3min\n",
      "[CV 3/5; 13/15] START logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 13/15] END logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.831 total time= 1.1min\n",
      "[CV 4/5; 14/15] START logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 14/15] END logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.814 total time= 2.9min\n",
      "[CV 2/5; 1/15] START logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 2/5; 1/15] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   2.7s\n",
      "[CV 4/5; 2/15] START logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 4/5; 2/15] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 3/5; 4/15] START logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 3/5; 4/15] END logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 1/5; 6/15] START logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 6/15] END logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.554 total time=   9.0s\n",
      "[CV 4/5; 7/15] START logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 7/15] END logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.556 total time=  25.5s\n",
      "[CV 2/5; 9/15] START logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 9/15] END logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.697 total time=  26.0s\n",
      "[CV 5/5; 10/15] START logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 10/15] END logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.780 total time= 2.0min\n",
      "[CV 5/5; 12/15] START logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 12/15] END logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.803 total time= 2.4min\n",
      "[CV 3/5; 15/15] START logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 15/15] END logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.833 total time= 2.0min\n",
      "[CV 3/5; 2/15] START logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 3/5; 2/15] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   2.9s\n",
      "[CV 2/5; 3/15] START logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 2/5; 3/15] END logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 2/5; 5/15] START logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs..\n",
      "[CV 2/5; 5/15] END logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 3/5; 6/15] START logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 6/15] END logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.556 total time=  11.7s\n",
      "[CV 2/5; 8/15] START logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 8/15] END logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.657 total time=  24.9s\n",
      "[CV 5/5; 9/15] START logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 9/15] END logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.753 total time=  26.7s\n",
      "[CV 3/5; 11/15] START logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 11/15] END logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.793 total time=  23.8s\n",
      "[CV 5/5; 11/15] START logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 11/15] END logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.803 total time=  27.4s\n",
      "[CV 3/5; 12/15] START logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 12/15] END logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.816 total time= 2.5min\n",
      "[CV 3/5; 14/15] START logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 14/15] END logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.835 total time= 2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/15] START logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 2/5; 2/15] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   2.6s\n",
      "[CV 5/5; 2/15] START logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 5/5; 2/15] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 2/5; 4/15] START logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 2/5; 4/15] END logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.3s\n",
      "[CV 5/5; 5/15] START logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs..\n",
      "[CV 5/5; 5/15] END logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.3s\n",
      "[CV 3/5; 7/15] START logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 7/15] END logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.556 total time=  31.2s\n",
      "[CV 1/5; 9/15] START logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 9/15] END logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.726 total time=  26.3s\n",
      "[CV 4/5; 10/15] START logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 10/15] END logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.837 total time= 2.0min\n",
      "[CV 4/5; 12/15] START logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 12/15] END logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.826 total time= 2.4min\n",
      "[CV 2/5; 15/15] START logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 15/15] END logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.856 total time= 2.0min\n",
      "[CV 5/5; 1/15] START logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 5/5; 1/15] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   3.0s\n",
      "[CV 1/5; 3/15] START logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 1/5; 3/15] END logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 5/5; 4/15] START logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 5/5; 4/15] END logreg__C=10.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 5/5; 6/15] START logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 6/15] END logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.556 total time=  10.4s\n",
      "[CV 5/5; 7/15] START logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 7/15] END logreg__C=0.01, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.556 total time=  28.5s\n",
      "[CV 1/5; 10/15] START logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 10/15] END logreg__C=1.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.810 total time= 2.4min\n",
      "[CV 1/5; 13/15] START logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 13/15] END logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.816 total time= 1.0min\n",
      "[CV 5/5; 13/15] START logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 13/15] END logreg__C=10.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.807 total time= 1.0min\n",
      "[CV 1/5; 15/15] START logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 15/15] END logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.808 total time= 2.1min\n",
      "[CV 5/5; 15/15] START logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 5/5; 15/15] END logreg__C=100.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.809 total time= 1.1min\n",
      "[CV 4/5; 1/15] START logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs...\n",
      "[CV 4/5; 1/15] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   3.0s\n",
      "[CV 4/5; 3/15] START logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs....\n",
      "[CV 4/5; 3/15] END logreg__C=1.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 1/5; 5/15] START logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs..\n",
      "[CV 1/5; 5/15] END logreg__C=100.0, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   1.4s\n",
      "[CV 4/5; 6/15] START logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 6/15] END logreg__C=0.01, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.556 total time=  11.6s\n",
      "[CV 1/5; 8/15] START logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 8/15] END logreg__C=0.1, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.728 total time=  23.3s\n",
      "[CV 3/5; 9/15] START logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 3/5; 9/15] END logreg__C=0.1, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.692 total time=  25.9s\n",
      "[CV 1/5; 11/15] START logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 1/5; 11/15] END logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.826 total time=  26.0s\n",
      "[CV 4/5; 11/15] START logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 4/5; 11/15] END logreg__C=1.0, logreg__penalty=l2, logreg__random_state=1, logreg__solver=saga;, score=0.851 total time=  23.5s\n",
      "[CV 2/5; 12/15] START logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 12/15] END logreg__C=10.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.845 total time= 2.5min\n",
      "[CV 2/5; 14/15] START logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga\n",
      "[CV 2/5; 14/15] END logreg__C=100.0, logreg__penalty=l1, logreg__random_state=1, logreg__solver=saga;, score=0.847 total time= 2.9min\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "17e91da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 10.0,\n",
       " 'logreg__penalty': 'l2',\n",
       " 'logreg__random_state': 1,\n",
       " 'logreg__solver': 'saga'}"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7aee61bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8308816434655227"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f367b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
