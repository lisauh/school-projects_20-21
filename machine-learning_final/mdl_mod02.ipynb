{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data files\n",
    "\n",
    "# has clean review text\n",
    "dataset = pd.read_json(\"dramainfo_revclean.json\")\n",
    "\n",
    "# tfidf\n",
    "tfidf_rev = np.load(\"tfidfvec.npy\")\n",
    "\n",
    "# word2vec\n",
    "w2v_rev = np.load(\"w2featvec.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'crew', 'ep_duration', 'episodes', 'genres', 'id',\n",
       "       'main_cast', 'num_ratings', 'num_watchers', 'orig_network', 'rating',\n",
       "       'reviews', 'synopsis', 'tags', 'title', 'year', 'romance',\n",
       "       'sitcom_comedy', 'comedy', 'war_historical', 'political_drama',\n",
       "       'thriller', 'friendship', 'melodrama_romance', 'drama', 'action',\n",
       "       'historical', 'youth_school', 'fantasy_supernatural_horror', 'mystery',\n",
       "       'life', 'family', 'clean_reviews'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start with genre = romance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtfidf_train, Xtfidf_test, ytfidf_train, ytfidf_test = train_test_split(tfidf_rev,\n",
    "                                                                        dataset.romance,\n",
    "                                                                        test_size=0.3,\n",
    "                                                                        random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xw2v_train, Xw2v_test, yw2v_train, yw2v_test = train_test_split(w2v_rev,\n",
    "                                                                dataset.romance,\n",
    "                                                                test_size=0.3,\n",
    "                                                                random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying different classifiers\n",
    "# adapted from:\n",
    "## https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"logreg\", LogisticRegression(max_iter=200)), \n",
    "          (\"rf\", RandomForestClassifier()),\n",
    "          (\"gnb\", GaussianNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = [\"accuracy\",\n",
    "           \"precision\",\n",
    "           \"recall\",\n",
    "           \"f1\",\n",
    "           \"roc_auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_models(X_train,y_train,X_test,y_test,models=models,scoring=scoring):\n",
    "    target_names = [\"is_not_genre\",\n",
    "                    \"is_genre\"]\n",
    "\n",
    "    result_dfs = []\n",
    "\n",
    "    for name, model in models:\n",
    "        # split data into sections\n",
    "        kfold = model_selection.KFold(n_splits=5,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=1)\n",
    "\n",
    "        # metrics for each fold\n",
    "        cv_results = model_selection.cross_validate(model,\n",
    "                                                    X_train,y_train,\n",
    "                                                    cv=kfold,\n",
    "                                                    scoring=scoring)\n",
    "\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # save each fold result to the list\n",
    "        model_df = pd.DataFrame(cv_results)\n",
    "        model_df['model'] = name\n",
    "        result_dfs.append(model_df)\n",
    "\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred,\n",
    "                                    target_names=target_names))\n",
    "\n",
    "    # single df of all results\n",
    "    return pd.concat(result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.84      0.55      0.67       444\n",
      "    is_genre       0.83      0.95      0.88       987\n",
      "\n",
      "    accuracy                           0.83      1431\n",
      "   macro avg       0.83      0.75      0.78      1431\n",
      "weighted avg       0.83      0.83      0.82      1431\n",
      "\n",
      "rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.90      0.25      0.39       444\n",
      "    is_genre       0.75      0.99      0.85       987\n",
      "\n",
      "    accuracy                           0.76      1431\n",
      "   macro avg       0.82      0.62      0.62      1431\n",
      "weighted avg       0.79      0.76      0.71      1431\n",
      "\n",
      "gnb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.57      0.32      0.41       444\n",
      "    is_genre       0.74      0.89      0.81       987\n",
      "\n",
      "    accuracy                           0.71      1431\n",
      "   macro avg       0.66      0.60      0.61      1431\n",
      "weighted avg       0.69      0.71      0.69      1431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_results = try_models(Xtfidf_train,ytfidf_train,Xtfidf_test,ytfidf_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gnb</th>\n",
       "      <td>0.690231</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.727299</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.873319</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.793582</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.584693</td>\n",
       "      <td>0.031364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.824744</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.820774</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.950285</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>0.880775</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>0.905740</td>\n",
       "      <td>0.006586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.747149</td>\n",
       "      <td>0.020366</td>\n",
       "      <td>0.735005</td>\n",
       "      <td>0.019695</td>\n",
       "      <td>0.984207</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.841416</td>\n",
       "      <td>0.013559</td>\n",
       "      <td>0.861579</td>\n",
       "      <td>0.021222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_accuracy           test_precision           test_recall            \\\n",
       "                mean       std           mean       std        mean       std   \n",
       "model                                                                           \n",
       "gnb         0.690231  0.017021       0.727299  0.014993    0.873319  0.009296   \n",
       "logreg      0.824744  0.008954       0.820774  0.010036    0.950285  0.007482   \n",
       "rf          0.747149  0.020366       0.735005  0.019695    0.984207  0.008986   \n",
       "\n",
       "         test_f1           test_roc_auc            \n",
       "            mean       std         mean       std  \n",
       "model                                              \n",
       "gnb     0.793582  0.010628     0.584693  0.031364  \n",
       "logreg  0.880775  0.008014     0.905740  0.006586  \n",
       "rf      0.841416  0.013559     0.861579  0.021222  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_results.groupby(\"model\")[[\"test_accuracy\", \"test_precision\", \"test_recall\",\n",
    "                                \"test_f1\", \"test_roc_auc\"]].agg([np.mean,np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.62      0.02      0.04       444\n",
      "    is_genre       0.69      0.99      0.82       987\n",
      "\n",
      "    accuracy                           0.69      1431\n",
      "   macro avg       0.65      0.51      0.43      1431\n",
      "weighted avg       0.67      0.69      0.57      1431\n",
      "\n",
      "rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.45      0.22      0.30       444\n",
      "    is_genre       0.71      0.88      0.79       987\n",
      "\n",
      "    accuracy                           0.67      1431\n",
      "   macro avg       0.58      0.55      0.54      1431\n",
      "weighted avg       0.63      0.67      0.63      1431\n",
      "\n",
      "gnb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.44      0.36      0.40       444\n",
      "    is_genre       0.73      0.79      0.76       987\n",
      "\n",
      "    accuracy                           0.66      1431\n",
      "   macro avg       0.59      0.58      0.58      1431\n",
      "weighted avg       0.64      0.66      0.65      1431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v_results = try_models(Xw2v_train,yw2v_train,Xw2v_test,yw2v_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gnb</th>\n",
       "      <td>0.653385</td>\n",
       "      <td>0.019428</td>\n",
       "      <td>0.727817</td>\n",
       "      <td>0.015276</td>\n",
       "      <td>0.785233</td>\n",
       "      <td>0.020271</td>\n",
       "      <td>0.755351</td>\n",
       "      <td>0.015366</td>\n",
       "      <td>0.637239</td>\n",
       "      <td>0.018981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.686338</td>\n",
       "      <td>0.017608</td>\n",
       "      <td>0.687096</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.991643</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.811656</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.652463</td>\n",
       "      <td>0.014830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.692629</td>\n",
       "      <td>0.023956</td>\n",
       "      <td>0.727245</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>0.879358</td>\n",
       "      <td>0.028457</td>\n",
       "      <td>0.795836</td>\n",
       "      <td>0.017215</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.030787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_accuracy           test_precision           test_recall            \\\n",
       "                mean       std           mean       std        mean       std   \n",
       "model                                                                           \n",
       "gnb         0.653385  0.019428       0.727817  0.015276    0.785233  0.020271   \n",
       "logreg      0.686338  0.017608       0.687096  0.016556    0.991643  0.004206   \n",
       "rf          0.692629  0.023956       0.727245  0.019564    0.879358  0.028457   \n",
       "\n",
       "         test_f1           test_roc_auc            \n",
       "            mean       std         mean       std  \n",
       "model                                              \n",
       "gnb     0.755351  0.015366     0.637239  0.018981  \n",
       "logreg  0.811656  0.011957     0.652463  0.014830  \n",
       "rf      0.795836  0.017215     0.693891  0.030787  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_results.groupby(\"model\")[[\"test_accuracy\", \"test_precision\", \"test_recall\",\n",
    "                                \"test_f1\", \"test_roc_auc\"]].agg([np.mean,np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6842105263157895"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.romance.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying again with genre = action\n",
    "\n",
    "to see if I need to upsample/downsample and perhaps combine more genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10589222059131893"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.action.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtfidf_train, Xtfidf_test, ytfidf_train, ytfidf_test = train_test_split(tfidf_rev,\n",
    "                                                                        dataset.action,\n",
    "                                                                        test_size=0.3,\n",
    "                                                                        random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xw2v_train, Xw2v_test, yw2v_train, yw2v_test = train_test_split(w2v_rev,\n",
    "                                                                dataset.action,\n",
    "                                                                test_size=0.3,\n",
    "                                                                random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.89      1.00      0.94      1276\n",
      "    is_genre       0.75      0.02      0.04       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.82      0.51      0.49      1431\n",
      "weighted avg       0.88      0.89      0.85      1431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_results2 = try_models(Xtfidf_train,ytfidf_train,Xtfidf_test,ytfidf_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay so i def need to upsample/downsample\n",
    "# and possibly delete/combine more genres <--- did this\n",
    "## which means i might have to run the pain w2v average function again ughughughguhg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ._."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "melodrama_romance              0.695324\n",
       "romance                        0.684211\n",
       "political_drama                0.525477\n",
       "drama                          0.513315\n",
       "sitcom_comedy                  0.369469\n",
       "comedy                         0.368421\n",
       "mystery                        0.153282\n",
       "youth_school                   0.150346\n",
       "fantasy_supernatural_horror    0.146152\n",
       "family                         0.143007\n",
       "war_historical                 0.132103\n",
       "historical                     0.130216\n",
       "friendship                     0.114280\n",
       "life                           0.114070\n",
       "action                         0.105892\n",
       "thriller                       0.102118\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:,16:-1].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying with stratified kfold, genres = romance, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_models2(X_train,y_train,X_test,y_test,models=models,scoring=scoring):\n",
    "    target_names = [\"is_not_genre\",\n",
    "                    \"is_genre\"]\n",
    "\n",
    "    result_dfs = []\n",
    "\n",
    "    for name, model in models:\n",
    "        # split data into sections\n",
    "        kfold = model_selection.StratifiedKFold(n_splits=5,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=1)\n",
    "\n",
    "        # metrics for each fold\n",
    "        cv_results = model_selection.cross_validate(model,\n",
    "                                                    X_train,y_train,\n",
    "                                                    groups=np.sort(y_train),\n",
    "                                                    cv=kfold,\n",
    "                                                    scoring=scoring)\n",
    "\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # save each fold result to the list\n",
    "        model_df = pd.DataFrame(cv_results)\n",
    "        model_df['model'] = name\n",
    "        result_dfs.append(model_df)\n",
    "\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred,\n",
    "                                    target_names=target_names))\n",
    "\n",
    "    # single df of all results\n",
    "    return pd.concat(result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.84      0.55      0.67       444\n",
      "    is_genre       0.83      0.95      0.88       987\n",
      "\n",
      "    accuracy                           0.83      1431\n",
      "   macro avg       0.83      0.75      0.78      1431\n",
      "weighted avg       0.83      0.83      0.82      1431\n",
      "\n",
      "rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.89      0.30      0.45       444\n",
      "    is_genre       0.76      0.98      0.86       987\n",
      "\n",
      "    accuracy                           0.77      1431\n",
      "   macro avg       0.82      0.64      0.65      1431\n",
      "weighted avg       0.80      0.77      0.73      1431\n",
      "\n",
      "gnb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "is_not_genre       0.57      0.32      0.41       444\n",
      "    is_genre       0.74      0.89      0.81       987\n",
      "\n",
      "    accuracy                           0.71      1431\n",
      "   macro avg       0.66      0.60      0.61      1431\n",
      "weighted avg       0.69      0.71      0.69      1431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_results_rom2 = try_models2(Xtfidf_train,ytfidf_train,Xtfidf_test,ytfidf_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gnb</th>\n",
       "      <td>0.690829</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.728565</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.871259</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.587678</td>\n",
       "      <td>0.012158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.825344</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>0.820790</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.951668</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>0.881378</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.907531</td>\n",
       "      <td>0.008578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.754645</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.738988</td>\n",
       "      <td>0.006825</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.846213</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.870064</td>\n",
       "      <td>0.012829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_accuracy           test_precision           test_recall            \\\n",
       "                mean       std           mean       std        mean       std   \n",
       "model                                                                           \n",
       "gnb         0.690829  0.008330       0.728565  0.006812    0.871259  0.010581   \n",
       "logreg      0.825344  0.008061       0.820790  0.006196    0.951668  0.008382   \n",
       "rf          0.754645  0.008228       0.738988  0.006825    0.989898  0.005503   \n",
       "\n",
       "         test_f1           test_roc_auc            \n",
       "            mean       std         mean       std  \n",
       "model                                              \n",
       "gnb     0.793507  0.005600     0.587678  0.012158  \n",
       "logreg  0.881378  0.005563     0.907531  0.008578  \n",
       "rf      0.846213  0.004479     0.870064  0.012829  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_results_rom2.groupby(\"model\")[[\"test_accuracy\", \"test_precision\", \"test_recall\",\n",
    "                                \"test_f1\", \"test_roc_auc\"]].agg([np.mean,np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for above romance\n",
    "# mostly the same, some differences in random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
