{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.1\n"
     ]
    }
   ],
   "source": [
    "# cuz i installed imblearn in the 3.9 folder\n",
    "# but i usually launch jupyter lab from the 3.8 folder\n",
    "## if 3.8, relaunch using: python3 -m notebook\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data files\n",
    "\n",
    "# has clean review text\n",
    "dataset = pd.read_json(\"dramainfo_revclean.json\")\n",
    "\n",
    "# tfidf\n",
    "tfidf_rev = np.load(\"tfidfvec.npy\")\n",
    "\n",
    "# word2vec\n",
    "w2v_rev = np.load(\"w2featvec.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "melodrama_romance              0.695324\n",
       "romance                        0.684211\n",
       "political_drama                0.525477\n",
       "drama                          0.513315\n",
       "sitcom_comedy                  0.369469\n",
       "comedy                         0.368421\n",
       "mystery                        0.153282\n",
       "youth_school                   0.150346\n",
       "fantasy_supernatural_horror    0.146152\n",
       "family                         0.143007\n",
       "war_historical                 0.132103\n",
       "historical                     0.130216\n",
       "friendship                     0.114280\n",
       "life                           0.114070\n",
       "action                         0.105892\n",
       "thriller                       0.102118\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no need for adjustment\n",
    "'''\n",
    "political_drama\n",
    "drama\n",
    "'''\n",
    "\n",
    "# undersample 1, oversample 0\n",
    "'''\n",
    "melodrama_romance\n",
    "romance\n",
    "'''\n",
    "\n",
    "# undersample 0, oversample 1\n",
    "'''\n",
    "sitcom_comedy\n",
    "comedy\n",
    "mystery\n",
    "youth_school\n",
    "fantasy_supernatural_horror\n",
    "family\n",
    "war_historical\n",
    "historical\n",
    "friendship\n",
    "life\n",
    "action\n",
    "thriller\n",
    "'''\n",
    "\n",
    "dataset.iloc[:,16:-1].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as imbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtfidf_train, Xtfidf_test, ytfidf_train, ytfidf_test = train_test_split(tfidf_rev,\n",
    "                                                                        dataset.action,\n",
    "                                                                        test_size=0.3,\n",
    "                                                                        random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2988, 1: 350})\n"
     ]
    }
   ],
   "source": [
    "target_counts = Counter(ytfidf_train)\n",
    "print(target_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_under_strat(minority,majority):\n",
    "    strat_lst = []\n",
    "    \n",
    "    over_ratio = np.round(minority/majority,2) + 0.1\n",
    "    \n",
    "    while over_ratio < 0.8:\n",
    "        strat_lst.append((over_ratio, 0.8))\n",
    "        over_ratio = over_ratio + 0.1\n",
    "    \n",
    "    strat_lst.append((0.8,0.8))\n",
    "    \n",
    "    return strat_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.22, 0.8),\n",
       " (0.32, 0.8),\n",
       " (0.42000000000000004, 0.8),\n",
       " (0.52, 0.8),\n",
       " (0.62, 0.8),\n",
       " (0.72, 0.8),\n",
       " (0.8, 0.8)]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_lst = over_under_strat(target_counts[1],target_counts[0])\n",
    "strat_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"logreg\", LogisticRegression(max_iter=200)), \n",
    "          (\"rf\", RandomForestClassifier()),\n",
    "          (\"gnb\", GaussianNB())]\n",
    "\n",
    "scoring = [\"accuracy\",\n",
    "           \"balanced_accuracy\",\n",
    "           \"precision\",\n",
    "           \"recall\",\n",
    "           \"f1\",\n",
    "           \"roc_auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(steps, X_train, y_train, X_test, scoring=scoring):\n",
    "    pipeline = imbPipeline(steps=steps)\n",
    "    \n",
    "    cv = model_selection.RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "    scores = model_selection.cross_validate(pipeline, X_train, y_train,\n",
    "                                            scoring=scoring, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    clf = pipeline.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    return scores, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ... logreg   0.22\n",
      "Running ... logreg   0.32\n",
      "Running ... logreg   0.42\n",
      "Running ... logreg   0.52\n",
      "Running ... logreg   0.62\n",
      "Running ... logreg   0.72\n",
      "Running ... logreg   0.8\n",
      "Running ... rf       0.22\n",
      "Running ... rf       0.32\n",
      "Running ... rf       0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ... rf       0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ... rf       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ... rf       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ... rf       0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ... gnb      0.22\n",
      "Running ... gnb      0.32\n",
      "Running ... gnb      0.42\n",
      "Running ... gnb      0.52\n",
      "Running ... gnb      0.62\n",
      "Running ... gnb      0.72\n",
      "Running ... gnb      0.8\n"
     ]
    }
   ],
   "source": [
    "result_dfs = []\n",
    "pred_list = []\n",
    "\n",
    "for name, model in models:\n",
    "    for over_strat, under_strat in strat_lst:\n",
    "        print(\"Running ... {:<9}{:<.2}\".format(name,over_strat))\n",
    "        steps = [(\"over\", RandomOverSampler(sampling_strategy=over_strat)),\n",
    "                 (\"under\",RandomUnderSampler(sampling_strategy=under_strat)),\n",
    "                 (name, model)]\n",
    "        result,pred = run_pipeline(steps,\n",
    "                                   Xtfidf_train,ytfidf_train,\n",
    "                                   Xtfidf_test)\n",
    "        model_df = pd.DataFrame(result)\n",
    "        model_df[\"model\"] = name\n",
    "        model_df[\"oversample_strat\"] = over_strat\n",
    "        result_dfs.append(model_df)\n",
    "\n",
    "        pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">fit_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_balanced_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>oversample_strat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">gnb</th>\n",
       "      <th>0.22</th>\n",
       "      <td>21.110729</td>\n",
       "      <td>9.441018</td>\n",
       "      <td>2.209390</td>\n",
       "      <td>0.525522</td>\n",
       "      <td>0.789097</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.580762</td>\n",
       "      <td>0.018094</td>\n",
       "      <td>0.192508</td>\n",
       "      <td>0.017216</td>\n",
       "      <td>0.317143</td>\n",
       "      <td>0.043016</td>\n",
       "      <td>0.239173</td>\n",
       "      <td>0.023783</td>\n",
       "      <td>0.580762</td>\n",
       "      <td>0.018094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>27.945038</td>\n",
       "      <td>12.150217</td>\n",
       "      <td>2.131880</td>\n",
       "      <td>0.593280</td>\n",
       "      <td>0.829840</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.558744</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>0.204089</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.215714</td>\n",
       "      <td>0.045897</td>\n",
       "      <td>0.209154</td>\n",
       "      <td>0.037595</td>\n",
       "      <td>0.558744</td>\n",
       "      <td>0.021848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>33.452614</td>\n",
       "      <td>15.091641</td>\n",
       "      <td>2.034965</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.847811</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.544820</td>\n",
       "      <td>0.018407</td>\n",
       "      <td>0.207493</td>\n",
       "      <td>0.034742</td>\n",
       "      <td>0.161429</td>\n",
       "      <td>0.040434</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.037818</td>\n",
       "      <td>0.544820</td>\n",
       "      <td>0.018407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.52</th>\n",
       "      <td>36.129575</td>\n",
       "      <td>15.864311</td>\n",
       "      <td>2.278499</td>\n",
       "      <td>0.661459</td>\n",
       "      <td>0.855899</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.536094</td>\n",
       "      <td>0.018616</td>\n",
       "      <td>0.204951</td>\n",
       "      <td>0.046745</td>\n",
       "      <td>0.131429</td>\n",
       "      <td>0.038568</td>\n",
       "      <td>0.159493</td>\n",
       "      <td>0.041602</td>\n",
       "      <td>0.536094</td>\n",
       "      <td>0.018616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.62</th>\n",
       "      <td>45.158232</td>\n",
       "      <td>20.026900</td>\n",
       "      <td>2.015513</td>\n",
       "      <td>0.564236</td>\n",
       "      <td>0.862490</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.534100</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.212880</td>\n",
       "      <td>0.058775</td>\n",
       "      <td>0.118571</td>\n",
       "      <td>0.043670</td>\n",
       "      <td>0.151847</td>\n",
       "      <td>0.050387</td>\n",
       "      <td>0.534100</td>\n",
       "      <td>0.021761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.72</th>\n",
       "      <td>77.374633</td>\n",
       "      <td>36.267202</td>\n",
       "      <td>1.803522</td>\n",
       "      <td>0.576432</td>\n",
       "      <td>0.865485</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>0.531359</td>\n",
       "      <td>0.018272</td>\n",
       "      <td>0.214806</td>\n",
       "      <td>0.055674</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.037008</td>\n",
       "      <td>0.143701</td>\n",
       "      <td>0.044396</td>\n",
       "      <td>0.531359</td>\n",
       "      <td>0.018272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>79.853122</td>\n",
       "      <td>36.810557</td>\n",
       "      <td>2.407952</td>\n",
       "      <td>0.870287</td>\n",
       "      <td>0.867131</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.528495</td>\n",
       "      <td>0.017941</td>\n",
       "      <td>0.214080</td>\n",
       "      <td>0.065945</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.034339</td>\n",
       "      <td>0.135771</td>\n",
       "      <td>0.044587</td>\n",
       "      <td>0.528495</td>\n",
       "      <td>0.017941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">logreg</th>\n",
       "      <th>0.22</th>\n",
       "      <td>20.224800</td>\n",
       "      <td>8.147673</td>\n",
       "      <td>0.243940</td>\n",
       "      <td>0.099017</td>\n",
       "      <td>0.895745</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.695827</td>\n",
       "      <td>0.030387</td>\n",
       "      <td>0.508276</td>\n",
       "      <td>0.042541</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.070630</td>\n",
       "      <td>0.468905</td>\n",
       "      <td>0.038974</td>\n",
       "      <td>0.871280</td>\n",
       "      <td>0.014713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>27.162181</td>\n",
       "      <td>10.396669</td>\n",
       "      <td>0.313554</td>\n",
       "      <td>0.171240</td>\n",
       "      <td>0.899339</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.697203</td>\n",
       "      <td>0.024554</td>\n",
       "      <td>0.529085</td>\n",
       "      <td>0.047589</td>\n",
       "      <td>0.441429</td>\n",
       "      <td>0.057321</td>\n",
       "      <td>0.477943</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>0.869043</td>\n",
       "      <td>0.016043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>35.822748</td>\n",
       "      <td>11.990034</td>\n",
       "      <td>0.348154</td>\n",
       "      <td>0.212228</td>\n",
       "      <td>0.899337</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.030520</td>\n",
       "      <td>0.524928</td>\n",
       "      <td>0.047033</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.063817</td>\n",
       "      <td>0.480055</td>\n",
       "      <td>0.049381</td>\n",
       "      <td>0.873836</td>\n",
       "      <td>0.015243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.52</th>\n",
       "      <td>152.861339</td>\n",
       "      <td>58.206517</td>\n",
       "      <td>0.413579</td>\n",
       "      <td>0.247714</td>\n",
       "      <td>0.902483</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.700221</td>\n",
       "      <td>0.030487</td>\n",
       "      <td>0.544186</td>\n",
       "      <td>0.054129</td>\n",
       "      <td>0.444286</td>\n",
       "      <td>0.061519</td>\n",
       "      <td>0.487589</td>\n",
       "      <td>0.051232</td>\n",
       "      <td>0.878101</td>\n",
       "      <td>0.014370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.62</th>\n",
       "      <td>201.801743</td>\n",
       "      <td>88.304647</td>\n",
       "      <td>0.369299</td>\n",
       "      <td>0.213062</td>\n",
       "      <td>0.903383</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.695679</td>\n",
       "      <td>0.033298</td>\n",
       "      <td>0.552528</td>\n",
       "      <td>0.057727</td>\n",
       "      <td>0.432857</td>\n",
       "      <td>0.069677</td>\n",
       "      <td>0.482722</td>\n",
       "      <td>0.055017</td>\n",
       "      <td>0.876944</td>\n",
       "      <td>0.015450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.72</th>\n",
       "      <td>298.382141</td>\n",
       "      <td>123.020734</td>\n",
       "      <td>0.412089</td>\n",
       "      <td>0.210972</td>\n",
       "      <td>0.904880</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.695885</td>\n",
       "      <td>0.030283</td>\n",
       "      <td>0.561464</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>0.431429</td>\n",
       "      <td>0.062379</td>\n",
       "      <td>0.486092</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.880806</td>\n",
       "      <td>0.014378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>358.215264</td>\n",
       "      <td>158.342680</td>\n",
       "      <td>0.380136</td>\n",
       "      <td>0.192550</td>\n",
       "      <td>0.905927</td>\n",
       "      <td>0.009006</td>\n",
       "      <td>0.698361</td>\n",
       "      <td>0.031841</td>\n",
       "      <td>0.568701</td>\n",
       "      <td>0.059211</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.065031</td>\n",
       "      <td>0.491382</td>\n",
       "      <td>0.054625</td>\n",
       "      <td>0.878918</td>\n",
       "      <td>0.014705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">rf</th>\n",
       "      <th>0.22</th>\n",
       "      <td>25.105655</td>\n",
       "      <td>10.245880</td>\n",
       "      <td>0.469073</td>\n",
       "      <td>0.168074</td>\n",
       "      <td>0.898592</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.549221</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>0.621007</td>\n",
       "      <td>0.158032</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.042191</td>\n",
       "      <td>0.178901</td>\n",
       "      <td>0.062345</td>\n",
       "      <td>0.800004</td>\n",
       "      <td>0.023736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>31.657221</td>\n",
       "      <td>12.670421</td>\n",
       "      <td>0.493433</td>\n",
       "      <td>0.149439</td>\n",
       "      <td>0.897094</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.518114</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>0.293452</td>\n",
       "      <td>0.038571</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>0.072696</td>\n",
       "      <td>0.033256</td>\n",
       "      <td>0.822932</td>\n",
       "      <td>0.022317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>40.220099</td>\n",
       "      <td>16.184407</td>\n",
       "      <td>0.543528</td>\n",
       "      <td>0.145720</td>\n",
       "      <td>0.896045</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.506808</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.466468</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>0.027818</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>0.826872</td>\n",
       "      <td>0.020593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.52</th>\n",
       "      <td>50.233886</td>\n",
       "      <td>20.149587</td>\n",
       "      <td>0.536880</td>\n",
       "      <td>0.174907</td>\n",
       "      <td>0.895895</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.504833</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.013553</td>\n",
       "      <td>0.019487</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>0.819403</td>\n",
       "      <td>0.026051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.62</th>\n",
       "      <td>54.561446</td>\n",
       "      <td>20.999399</td>\n",
       "      <td>0.509527</td>\n",
       "      <td>0.154131</td>\n",
       "      <td>0.895297</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.501345</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.006023</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>0.822829</td>\n",
       "      <td>0.027852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.72</th>\n",
       "      <td>81.002549</td>\n",
       "      <td>33.300063</td>\n",
       "      <td>0.553219</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.895296</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.500714</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.820791</td>\n",
       "      <td>0.025079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>127.798042</td>\n",
       "      <td>55.629144</td>\n",
       "      <td>0.786164</td>\n",
       "      <td>0.522189</td>\n",
       "      <td>0.895147</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829987</td>\n",
       "      <td>0.019526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           fit_time             score_time            \\\n",
       "                               mean         std       mean       std   \n",
       "model  oversample_strat                                                \n",
       "gnb    0.22               21.110729    9.441018   2.209390  0.525522   \n",
       "       0.32               27.945038   12.150217   2.131880  0.593280   \n",
       "       0.42               33.452614   15.091641   2.034965  0.565789   \n",
       "       0.52               36.129575   15.864311   2.278499  0.661459   \n",
       "       0.62               45.158232   20.026900   2.015513  0.564236   \n",
       "       0.72               77.374633   36.267202   1.803522  0.576432   \n",
       "       0.80               79.853122   36.810557   2.407952  0.870287   \n",
       "logreg 0.22               20.224800    8.147673   0.243940  0.099017   \n",
       "       0.32               27.162181   10.396669   0.313554  0.171240   \n",
       "       0.42               35.822748   11.990034   0.348154  0.212228   \n",
       "       0.52              152.861339   58.206517   0.413579  0.247714   \n",
       "       0.62              201.801743   88.304647   0.369299  0.213062   \n",
       "       0.72              298.382141  123.020734   0.412089  0.210972   \n",
       "       0.80              358.215264  158.342680   0.380136  0.192550   \n",
       "rf     0.22               25.105655   10.245880   0.469073  0.168074   \n",
       "       0.32               31.657221   12.670421   0.493433  0.149439   \n",
       "       0.42               40.220099   16.184407   0.543528  0.145720   \n",
       "       0.52               50.233886   20.149587   0.536880  0.174907   \n",
       "       0.62               54.561446   20.999399   0.509527  0.154131   \n",
       "       0.72               81.002549   33.300063   0.553219  0.227000   \n",
       "       0.80              127.798042   55.629144   0.786164  0.522189   \n",
       "\n",
       "                        test_accuracy           test_balanced_accuracy  \\\n",
       "                                 mean       std                   mean   \n",
       "model  oversample_strat                                                  \n",
       "gnb    0.22                  0.789097  0.010631               0.580762   \n",
       "       0.32                  0.829840  0.009449               0.558744   \n",
       "       0.42                  0.847811  0.008540               0.544820   \n",
       "       0.52                  0.855899  0.006999               0.536094   \n",
       "       0.62                  0.862490  0.006291               0.534100   \n",
       "       0.72                  0.865485  0.006226               0.531359   \n",
       "       0.80                  0.867131  0.008380               0.528495   \n",
       "logreg 0.22                  0.895745  0.007230               0.695827   \n",
       "       0.32                  0.899339  0.007791               0.697203   \n",
       "       0.42                  0.899337  0.008403               0.699094   \n",
       "       0.52                  0.902483  0.009150               0.700221   \n",
       "       0.62                  0.903383  0.009269               0.695679   \n",
       "       0.72                  0.904880  0.008004               0.695885   \n",
       "       0.80                  0.905927  0.009006               0.698361   \n",
       "rf     0.22                  0.898592  0.005988               0.549221   \n",
       "       0.32                  0.897094  0.003407               0.518114   \n",
       "       0.42                  0.896045  0.001795               0.506808   \n",
       "       0.52                  0.895895  0.001796               0.504833   \n",
       "       0.62                  0.895297  0.000804               0.501345   \n",
       "       0.72                  0.895296  0.000502               0.500714   \n",
       "       0.80                  0.895147  0.000081               0.500000   \n",
       "\n",
       "                                  test_precision           test_recall  \\\n",
       "                              std           mean       std        mean   \n",
       "model  oversample_strat                                                  \n",
       "gnb    0.22              0.018094       0.192508  0.017216    0.317143   \n",
       "       0.32              0.021848       0.204089  0.032902    0.215714   \n",
       "       0.42              0.018407       0.207493  0.034742    0.161429   \n",
       "       0.52              0.018616       0.204951  0.046745    0.131429   \n",
       "       0.62              0.021761       0.212880  0.058775    0.118571   \n",
       "       0.72              0.018272       0.214806  0.055674    0.108571   \n",
       "       0.80              0.017941       0.214080  0.065945    0.100000   \n",
       "logreg 0.22              0.030387       0.508276  0.042541    0.442857   \n",
       "       0.32              0.024554       0.529085  0.047589    0.441429   \n",
       "       0.42              0.030520       0.524928  0.047033    0.445714   \n",
       "       0.52              0.030487       0.544186  0.054129    0.444286   \n",
       "       0.62              0.033298       0.552528  0.057727    0.432857   \n",
       "       0.72              0.030283       0.561464  0.051591    0.431429   \n",
       "       0.80              0.031841       0.568701  0.059211    0.435714   \n",
       "rf     0.22              0.020371       0.621007  0.158032    0.107143   \n",
       "       0.32              0.009630       0.678333  0.293452    0.038571   \n",
       "       0.42              0.005974       0.583333  0.466468    0.014286   \n",
       "       0.52              0.006921       0.500000  0.527046    0.010000   \n",
       "       0.62              0.003067       0.200000  0.421637    0.002857   \n",
       "       0.72              0.002259       0.100000  0.316228    0.001429   \n",
       "       0.80              0.000000       0.000000  0.000000    0.000000   \n",
       "\n",
       "                                    test_f1           test_roc_auc            \n",
       "                              std      mean       std         mean       std  \n",
       "model  oversample_strat                                                       \n",
       "gnb    0.22              0.043016  0.239173  0.023783     0.580762  0.018094  \n",
       "       0.32              0.045897  0.209154  0.037595     0.558744  0.021848  \n",
       "       0.42              0.040434  0.180700  0.037818     0.544820  0.018407  \n",
       "       0.52              0.038568  0.159493  0.041602     0.536094  0.018616  \n",
       "       0.62              0.043670  0.151847  0.050387     0.534100  0.021761  \n",
       "       0.72              0.037008  0.143701  0.044396     0.531359  0.018272  \n",
       "       0.80              0.034339  0.135771  0.044587     0.528495  0.017941  \n",
       "logreg 0.22              0.070630  0.468905  0.038974     0.871280  0.014713  \n",
       "       0.32              0.057321  0.477943  0.033603     0.869043  0.016043  \n",
       "       0.42              0.063817  0.480055  0.049381     0.873836  0.015243  \n",
       "       0.52              0.061519  0.487589  0.051232     0.878101  0.014370  \n",
       "       0.62              0.069677  0.482722  0.055017     0.876944  0.015450  \n",
       "       0.72              0.062379  0.486092  0.050949     0.880806  0.014378  \n",
       "       0.80              0.065031  0.491382  0.054625     0.878918  0.014705  \n",
       "rf     0.22              0.042191  0.178901  0.062345     0.800004  0.023736  \n",
       "       0.32              0.017881  0.072696  0.033256     0.822932  0.022317  \n",
       "       0.42              0.011664  0.027818  0.022682     0.826872  0.020593  \n",
       "       0.52              0.013553  0.019487  0.026103     0.819403  0.026051  \n",
       "       0.62              0.006023  0.005634  0.011877     0.822829  0.027852  \n",
       "       0.72              0.004518  0.002817  0.008908     0.820791  0.025079  \n",
       "       0.80              0.000000  0.000000  0.000000     0.829987  0.019526  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_grp = results.groupby([\"model\",\"oversample_strat\"]).agg([np.mean,np.std])\n",
    "results_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "logreg   0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      1276\n",
      "           1       0.47      0.48      0.47       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.70      0.71      0.71      1431\n",
      "weighted avg       0.89      0.89      0.89      1431\n",
      "\n",
      "\n",
      "logreg   0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1276\n",
      "           1       0.50      0.48      0.49       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.72      0.71      0.71      1431\n",
      "weighted avg       0.89      0.89      0.89      1431\n",
      "\n",
      "\n",
      "logreg   0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1276\n",
      "           1       0.47      0.46      0.47       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.70      0.70      0.70      1431\n",
      "weighted avg       0.89      0.89      0.89      1431\n",
      "\n",
      "\n",
      "logreg   0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1276\n",
      "           1       0.51      0.46      0.48       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.72      0.70      0.71      1431\n",
      "weighted avg       0.89      0.89      0.89      1431\n",
      "\n",
      "\n",
      "logreg   0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      1276\n",
      "           1       0.54      0.49      0.51       155\n",
      "\n",
      "    accuracy                           0.90      1431\n",
      "   macro avg       0.74      0.72      0.73      1431\n",
      "weighted avg       0.90      0.90      0.90      1431\n",
      "\n",
      "\n",
      "logreg   0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      1276\n",
      "           1       0.55      0.46      0.50       155\n",
      "\n",
      "    accuracy                           0.90      1431\n",
      "   macro avg       0.74      0.71      0.72      1431\n",
      "weighted avg       0.89      0.90      0.90      1431\n",
      "\n",
      "\n",
      "logreg   0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1276\n",
      "           1       0.53      0.45      0.49       155\n",
      "\n",
      "    accuracy                           0.90      1431\n",
      "   macro avg       0.73      0.70      0.71      1431\n",
      "weighted avg       0.89      0.90      0.89      1431\n",
      "\n",
      "\n",
      "rf       0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      1276\n",
      "           1       0.50      0.10      0.17       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.70      0.55      0.56      1431\n",
      "weighted avg       0.86      0.89      0.86      1431\n",
      "\n",
      "\n",
      "rf       0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      1276\n",
      "           1       0.69      0.06      0.11       155\n",
      "\n",
      "    accuracy                           0.90      1431\n",
      "   macro avg       0.79      0.53      0.53      1431\n",
      "weighted avg       0.87      0.90      0.85      1431\n",
      "\n",
      "\n",
      "rf       0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1276\n",
      "           1       1.00      0.01      0.01       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.95      0.50      0.48      1431\n",
      "weighted avg       0.90      0.89      0.84      1431\n",
      "\n",
      "\n",
      "rf       0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1276\n",
      "           1       1.00      0.01      0.01       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.95      0.50      0.48      1431\n",
      "weighted avg       0.90      0.89      0.84      1431\n",
      "\n",
      "\n",
      "rf       0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1276\n",
      "           1       1.00      0.01      0.01       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.95      0.50      0.48      1431\n",
      "weighted avg       0.90      0.89      0.84      1431\n",
      "\n",
      "\n",
      "rf       0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1276\n",
      "           1       1.00      0.01      0.01       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.95      0.50      0.48      1431\n",
      "weighted avg       0.90      0.89      0.84      1431\n",
      "\n",
      "\n",
      "rf       0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1276\n",
      "           1       0.00      0.00      0.00       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.45      0.50      0.47      1431\n",
      "weighted avg       0.80      0.89      0.84      1431\n",
      "\n",
      "\n",
      "gnb      0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88      1276\n",
      "           1       0.20      0.32      0.25       155\n",
      "\n",
      "    accuracy                           0.79      1431\n",
      "   macro avg       0.56      0.58      0.56      1431\n",
      "weighted avg       0.83      0.79      0.81      1431\n",
      "\n",
      "\n",
      "gnb      0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90      1276\n",
      "           1       0.18      0.17      0.17       155\n",
      "\n",
      "    accuracy                           0.83      1431\n",
      "   macro avg       0.54      0.54      0.54      1431\n",
      "weighted avg       0.82      0.83      0.82      1431\n",
      "\n",
      "\n",
      "gnb      0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1276\n",
      "           1       0.18      0.14      0.16       155\n",
      "\n",
      "    accuracy                           0.84      1431\n",
      "   macro avg       0.54      0.53      0.53      1431\n",
      "weighted avg       0.82      0.84      0.83      1431\n",
      "\n",
      "\n",
      "gnb      0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      1276\n",
      "           1       0.22      0.14      0.17       155\n",
      "\n",
      "    accuracy                           0.85      1431\n",
      "   macro avg       0.56      0.54      0.54      1431\n",
      "weighted avg       0.83      0.85      0.84      1431\n",
      "\n",
      "\n",
      "gnb      0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      1276\n",
      "           1       0.17      0.10      0.12       155\n",
      "\n",
      "    accuracy                           0.85      1431\n",
      "   macro avg       0.54      0.52      0.52      1431\n",
      "weighted avg       0.82      0.85      0.83      1431\n",
      "\n",
      "\n",
      "gnb      0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1276\n",
      "           1       0.18      0.10      0.13       155\n",
      "\n",
      "    accuracy                           0.86      1431\n",
      "   macro avg       0.54      0.52      0.52      1431\n",
      "weighted avg       0.82      0.86      0.84      1431\n",
      "\n",
      "\n",
      "gnb      0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1276\n",
      "           1       0.20      0.10      0.13       155\n",
      "\n",
      "    accuracy                           0.86      1431\n",
      "   macro avg       0.55      0.52      0.53      1431\n",
      "weighted avg       0.82      0.86      0.84      1431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_list)):\n",
    "    name = models[int(i/len(strat_lst))][0]\n",
    "    oversamp = strat_lst[i%7][0]\n",
    "    \n",
    "    print(\"\\n{:<9}{:<.2}\".format(name,oversamp))\n",
    "    print(classification_report(ytfidf_test, pred_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression seems to do the best\n",
    "# should upsample to at least around 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xw2v_train, Xw2v_test, yw2v_train, yw2v_test = train_test_split(w2v_rev,\n",
    "                                                                dataset.action,\n",
    "                                                                test_size=0.3,\n",
    "                                                                random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2988, 1: 350})\n"
     ]
    }
   ],
   "source": [
    "target_counts2 = Counter(yw2v_train)\n",
    "print(target_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.22, 0.8),\n",
       " (0.32, 0.8),\n",
       " (0.42000000000000004, 0.8),\n",
       " (0.52, 0.8),\n",
       " (0.62, 0.8),\n",
       " (0.72, 0.8),\n",
       " (0.8, 0.8)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_lst2 = over_under_strat(target_counts2[1],target_counts2[0])\n",
    "strat_lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ... logreg   0.22\n",
      "Running ... logreg   0.32\n",
      "Running ... logreg   0.42\n",
      "Running ... logreg   0.52\n",
      "Running ... logreg   0.62\n",
      "Running ... logreg   0.72\n",
      "Running ... logreg   0.8\n",
      "Running ... rf       0.22\n",
      "Running ... rf       0.32\n",
      "Running ... rf       0.42\n",
      "Running ... rf       0.52\n",
      "Running ... rf       0.62\n",
      "Running ... rf       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ... rf       0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ... gnb      0.22\n",
      "Running ... gnb      0.32\n",
      "Running ... gnb      0.42\n",
      "Running ... gnb      0.52\n",
      "Running ... gnb      0.62\n",
      "Running ... gnb      0.72\n",
      "Running ... gnb      0.8\n"
     ]
    }
   ],
   "source": [
    "result_dfs2 = []\n",
    "pred_list2 = []\n",
    "\n",
    "for name, model in models:\n",
    "    for over_strat, under_strat in strat_lst2:\n",
    "        print(\"Running ... {:<9}{:<.2}\".format(name,over_strat))\n",
    "        steps = [(\"over\", RandomOverSampler(sampling_strategy=over_strat)),\n",
    "                 (\"under\",RandomUnderSampler(sampling_strategy=under_strat)),\n",
    "                 (name, model)]\n",
    "        result,pred = run_pipeline(steps,\n",
    "                                   Xw2v_train,yw2v_train,\n",
    "                                   Xw2v_test)\n",
    "        model_df = pd.DataFrame(result)\n",
    "        model_df[\"model\"] = name\n",
    "        model_df[\"oversample_strat\"] = over_strat\n",
    "        result_dfs2.append(model_df)\n",
    "\n",
    "        pred_list2.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.concat(result_dfs2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">fit_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_balanced_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>oversample_strat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">gnb</th>\n",
       "      <th>0.22</th>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.489068</td>\n",
       "      <td>0.127958</td>\n",
       "      <td>0.518489</td>\n",
       "      <td>0.026849</td>\n",
       "      <td>0.113318</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>0.555714</td>\n",
       "      <td>0.145133</td>\n",
       "      <td>0.185688</td>\n",
       "      <td>0.013093</td>\n",
       "      <td>0.536148</td>\n",
       "      <td>0.045899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.390204</td>\n",
       "      <td>0.071543</td>\n",
       "      <td>0.510562</td>\n",
       "      <td>0.025109</td>\n",
       "      <td>0.108483</td>\n",
       "      <td>0.008449</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.080306</td>\n",
       "      <td>0.185992</td>\n",
       "      <td>0.012151</td>\n",
       "      <td>0.545694</td>\n",
       "      <td>0.047742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>0.010231</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.400682</td>\n",
       "      <td>0.079361</td>\n",
       "      <td>0.517044</td>\n",
       "      <td>0.041681</td>\n",
       "      <td>0.110831</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>0.664286</td>\n",
       "      <td>0.092152</td>\n",
       "      <td>0.189389</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.533354</td>\n",
       "      <td>0.051477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.52</th>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.415069</td>\n",
       "      <td>0.051363</td>\n",
       "      <td>0.527604</td>\n",
       "      <td>0.048198</td>\n",
       "      <td>0.113676</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.085303</td>\n",
       "      <td>0.194188</td>\n",
       "      <td>0.024052</td>\n",
       "      <td>0.551037</td>\n",
       "      <td>0.055866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.62</th>\n",
       "      <td>0.012750</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.444431</td>\n",
       "      <td>0.096333</td>\n",
       "      <td>0.537698</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.118627</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>0.655714</td>\n",
       "      <td>0.104426</td>\n",
       "      <td>0.199698</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.556431</td>\n",
       "      <td>0.048026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.72</th>\n",
       "      <td>0.013662</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.404280</td>\n",
       "      <td>0.066049</td>\n",
       "      <td>0.526622</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>0.681429</td>\n",
       "      <td>0.077386</td>\n",
       "      <td>0.194497</td>\n",
       "      <td>0.022381</td>\n",
       "      <td>0.545073</td>\n",
       "      <td>0.053974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.012003</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.429597</td>\n",
       "      <td>0.078433</td>\n",
       "      <td>0.538871</td>\n",
       "      <td>0.040723</td>\n",
       "      <td>0.118197</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>0.677143</td>\n",
       "      <td>0.094329</td>\n",
       "      <td>0.200406</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>0.555370</td>\n",
       "      <td>0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">logreg</th>\n",
       "      <th>0.22</th>\n",
       "      <td>0.024860</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.849758</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>0.514376</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>0.147352</td>\n",
       "      <td>0.038417</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.033026</td>\n",
       "      <td>0.109970</td>\n",
       "      <td>0.033015</td>\n",
       "      <td>0.597543</td>\n",
       "      <td>0.029759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>0.027563</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.817859</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.521154</td>\n",
       "      <td>0.021818</td>\n",
       "      <td>0.139992</td>\n",
       "      <td>0.038498</td>\n",
       "      <td>0.145714</td>\n",
       "      <td>0.050305</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.042510</td>\n",
       "      <td>0.601043</td>\n",
       "      <td>0.025349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.814111</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>0.522213</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.140492</td>\n",
       "      <td>0.026727</td>\n",
       "      <td>0.152857</td>\n",
       "      <td>0.039297</td>\n",
       "      <td>0.145789</td>\n",
       "      <td>0.031520</td>\n",
       "      <td>0.599422</td>\n",
       "      <td>0.038135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.52</th>\n",
       "      <td>0.045337</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.808272</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.535347</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>0.157212</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.032332</td>\n",
       "      <td>0.171717</td>\n",
       "      <td>0.026102</td>\n",
       "      <td>0.607820</td>\n",
       "      <td>0.021498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.62</th>\n",
       "      <td>0.064383</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>0.527096</td>\n",
       "      <td>0.018411</td>\n",
       "      <td>0.141886</td>\n",
       "      <td>0.024981</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>0.160527</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.607404</td>\n",
       "      <td>0.033067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.72</th>\n",
       "      <td>0.084620</td>\n",
       "      <td>0.023317</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.797188</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.536723</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>0.152725</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.207143</td>\n",
       "      <td>0.043773</td>\n",
       "      <td>0.175404</td>\n",
       "      <td>0.029623</td>\n",
       "      <td>0.608891</td>\n",
       "      <td>0.031007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.100464</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>0.790147</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.533421</td>\n",
       "      <td>0.019609</td>\n",
       "      <td>0.146583</td>\n",
       "      <td>0.022866</td>\n",
       "      <td>0.208571</td>\n",
       "      <td>0.043747</td>\n",
       "      <td>0.171737</td>\n",
       "      <td>0.029445</td>\n",
       "      <td>0.611035</td>\n",
       "      <td>0.029602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">rf</th>\n",
       "      <th>0.22</th>\n",
       "      <td>0.660052</td>\n",
       "      <td>0.090416</td>\n",
       "      <td>0.034865</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.817108</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.530192</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>0.158466</td>\n",
       "      <td>0.038954</td>\n",
       "      <td>0.167143</td>\n",
       "      <td>0.030155</td>\n",
       "      <td>0.161629</td>\n",
       "      <td>0.031510</td>\n",
       "      <td>0.602748</td>\n",
       "      <td>0.023558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>0.921280</td>\n",
       "      <td>0.119706</td>\n",
       "      <td>0.036083</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.867737</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.514959</td>\n",
       "      <td>0.015581</td>\n",
       "      <td>0.169739</td>\n",
       "      <td>0.062292</td>\n",
       "      <td>0.068571</td>\n",
       "      <td>0.034863</td>\n",
       "      <td>0.096222</td>\n",
       "      <td>0.043051</td>\n",
       "      <td>0.616759</td>\n",
       "      <td>0.028799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>1.181492</td>\n",
       "      <td>0.155643</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.883764</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.517605</td>\n",
       "      <td>0.010495</td>\n",
       "      <td>0.246418</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>0.024094</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>0.608033</td>\n",
       "      <td>0.025398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.52</th>\n",
       "      <td>1.456925</td>\n",
       "      <td>0.201010</td>\n",
       "      <td>0.036746</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.890353</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.509305</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.282976</td>\n",
       "      <td>0.118289</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.049210</td>\n",
       "      <td>0.018631</td>\n",
       "      <td>0.609794</td>\n",
       "      <td>0.036326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.62</th>\n",
       "      <td>1.763797</td>\n",
       "      <td>0.261399</td>\n",
       "      <td>0.036721</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.893349</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.507825</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>0.328029</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.019284</td>\n",
       "      <td>0.037148</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0.612131</td>\n",
       "      <td>0.031475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.72</th>\n",
       "      <td>2.043051</td>\n",
       "      <td>0.310314</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.893948</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.503745</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.019295</td>\n",
       "      <td>0.013320</td>\n",
       "      <td>0.605847</td>\n",
       "      <td>0.037996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>2.243885</td>\n",
       "      <td>0.309508</td>\n",
       "      <td>0.036165</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.894997</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.504961</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.444667</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.022003</td>\n",
       "      <td>0.021439</td>\n",
       "      <td>0.611658</td>\n",
       "      <td>0.032082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fit_time           score_time            \\\n",
       "                             mean       std       mean       std   \n",
       "model  oversample_strat                                            \n",
       "gnb    0.22              0.006684  0.001502   0.005805  0.002440   \n",
       "       0.32              0.010896  0.003072   0.008961  0.004188   \n",
       "       0.42              0.010231  0.004272   0.006271  0.001987   \n",
       "       0.52              0.011836  0.003489   0.007639  0.002551   \n",
       "       0.62              0.012750  0.005084   0.007163  0.002667   \n",
       "       0.72              0.013662  0.004214   0.006118  0.001581   \n",
       "       0.80              0.012003  0.002696   0.005860  0.001809   \n",
       "logreg 0.22              0.024860  0.007985   0.005538  0.002836   \n",
       "       0.32              0.027563  0.006714   0.003403  0.000130   \n",
       "       0.42              0.033913  0.011346   0.003464  0.000181   \n",
       "       0.52              0.045337  0.009021   0.004429  0.001857   \n",
       "       0.62              0.064383  0.017667   0.005211  0.002976   \n",
       "       0.72              0.084620  0.023317   0.005686  0.004076   \n",
       "       0.80              0.100464  0.033036   0.004950  0.003059   \n",
       "rf     0.22              0.660052  0.090416   0.034865  0.006583   \n",
       "       0.32              0.921280  0.119706   0.036083  0.006035   \n",
       "       0.42              1.181492  0.155643   0.034284  0.007452   \n",
       "       0.52              1.456925  0.201010   0.036746  0.008508   \n",
       "       0.62              1.763797  0.261399   0.036721  0.009146   \n",
       "       0.72              2.043051  0.310314   0.035242  0.008151   \n",
       "       0.80              2.243885  0.309508   0.036165  0.008475   \n",
       "\n",
       "                        test_accuracy           test_balanced_accuracy  \\\n",
       "                                 mean       std                   mean   \n",
       "model  oversample_strat                                                  \n",
       "gnb    0.22                  0.489068  0.127958               0.518489   \n",
       "       0.32                  0.390204  0.071543               0.510562   \n",
       "       0.42                  0.400682  0.079361               0.517044   \n",
       "       0.52                  0.415069  0.051363               0.527604   \n",
       "       0.62                  0.444431  0.096333               0.537698   \n",
       "       0.72                  0.404280  0.066049               0.526622   \n",
       "       0.80                  0.429597  0.078433               0.538871   \n",
       "logreg 0.22                  0.849758  0.012463               0.514376   \n",
       "       0.32                  0.817859  0.014262               0.521154   \n",
       "       0.42                  0.814111  0.011198               0.522213   \n",
       "       0.52                  0.808272  0.009841               0.535347   \n",
       "       0.62                  0.796887  0.011286               0.527096   \n",
       "       0.72                  0.797188  0.009569               0.536723   \n",
       "       0.80                  0.790147  0.011982               0.533421   \n",
       "rf     0.22                  0.817108  0.018393               0.530192   \n",
       "       0.32                  0.867737  0.008146               0.514959   \n",
       "       0.42                  0.883764  0.004159               0.517605   \n",
       "       0.52                  0.890353  0.002809               0.509305   \n",
       "       0.62                  0.893349  0.002730               0.507825   \n",
       "       0.72                  0.893948  0.001699               0.503745   \n",
       "       0.80                  0.894997  0.001449               0.504961   \n",
       "\n",
       "                                  test_precision           test_recall  \\\n",
       "                              std           mean       std        mean   \n",
       "model  oversample_strat                                                  \n",
       "gnb    0.22              0.026849       0.113318  0.010184    0.555714   \n",
       "       0.32              0.025109       0.108483  0.008449    0.662857   \n",
       "       0.42              0.041681       0.110831  0.013154    0.664286   \n",
       "       0.52              0.048198       0.113676  0.014604    0.670000   \n",
       "       0.62              0.035075       0.118627  0.014798    0.655714   \n",
       "       0.72              0.043564       0.113727  0.014766    0.681429   \n",
       "       0.80              0.040723       0.118197  0.015216    0.677143   \n",
       "logreg 0.22              0.013278       0.147352  0.038417    0.090000   \n",
       "       0.32              0.021818       0.139992  0.038498    0.145714   \n",
       "       0.42              0.015896       0.140492  0.026727    0.152857   \n",
       "       0.52              0.015424       0.157212  0.023548    0.190000   \n",
       "       0.62              0.018411       0.141886  0.024981    0.185714   \n",
       "       0.72              0.018763       0.152725  0.022124    0.207143   \n",
       "       0.80              0.019609       0.146583  0.022866    0.208571   \n",
       "rf     0.22              0.018562       0.158466  0.038954    0.167143   \n",
       "       0.32              0.015581       0.169739  0.062292    0.068571   \n",
       "       0.42              0.010495       0.246418  0.060837    0.054286   \n",
       "       0.52              0.005455       0.282976  0.118289    0.027143   \n",
       "       0.62              0.009476       0.353333  0.328029    0.020000   \n",
       "       0.72              0.003472       0.333333  0.311805    0.010000   \n",
       "       0.80              0.005359       0.440000  0.444667    0.011429   \n",
       "\n",
       "                                    test_f1           test_roc_auc            \n",
       "                              std      mean       std         mean       std  \n",
       "model  oversample_strat                                                       \n",
       "gnb    0.22              0.145133  0.185688  0.013093     0.536148  0.045899  \n",
       "       0.32              0.080306  0.185992  0.012151     0.545694  0.047742  \n",
       "       0.42              0.092152  0.189389  0.020200     0.533354  0.051477  \n",
       "       0.52              0.085303  0.194188  0.024052     0.551037  0.055866  \n",
       "       0.62              0.104426  0.199698  0.019737     0.556431  0.048026  \n",
       "       0.72              0.077386  0.194497  0.022381     0.545073  0.053974  \n",
       "       0.80              0.094329  0.200406  0.021647     0.555370  0.049118  \n",
       "logreg 0.22              0.033026  0.109970  0.033015     0.597543  0.029759  \n",
       "       0.32              0.050305  0.141800  0.042510     0.601043  0.025349  \n",
       "       0.42              0.039297  0.145789  0.031520     0.599422  0.038135  \n",
       "       0.52              0.032332  0.171717  0.026102     0.607820  0.021498  \n",
       "       0.62              0.037495  0.160527  0.029094     0.607404  0.033067  \n",
       "       0.72              0.043773  0.175404  0.029623     0.608891  0.031007  \n",
       "       0.80              0.043747  0.171737  0.029445     0.611035  0.029602  \n",
       "rf     0.22              0.030155  0.161629  0.031510     0.602748  0.023558  \n",
       "       0.32              0.034863  0.096222  0.043051     0.616759  0.028799  \n",
       "       0.42              0.024094  0.087882  0.034743     0.608033  0.025398  \n",
       "       0.52              0.010541  0.049210  0.018631     0.609794  0.036326  \n",
       "       0.62              0.019284  0.037148  0.035110     0.612131  0.031475  \n",
       "       0.72              0.006901  0.019295  0.013320     0.605847  0.037996  \n",
       "       0.80              0.011269  0.022003  0.021439     0.611658  0.032082  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_grp2 = results2.groupby([\"model\",\"oversample_strat\"]).agg([np.mean,np.std])\n",
    "results_grp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "logreg   0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1276\n",
      "           1       0.15      0.12      0.14       155\n",
      "\n",
      "    accuracy                           0.83      1431\n",
      "   macro avg       0.53      0.52      0.52      1431\n",
      "weighted avg       0.82      0.83      0.82      1431\n",
      "\n",
      "\n",
      "logreg   0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      1276\n",
      "           1       0.16      0.15      0.15       155\n",
      "\n",
      "    accuracy                           0.82      1431\n",
      "   macro avg       0.53      0.53      0.53      1431\n",
      "weighted avg       0.82      0.82      0.82      1431\n",
      "\n",
      "\n",
      "logreg   0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      1276\n",
      "           1       0.16      0.17      0.17       155\n",
      "\n",
      "    accuracy                           0.81      1431\n",
      "   macro avg       0.53      0.53      0.53      1431\n",
      "weighted avg       0.82      0.81      0.82      1431\n",
      "\n",
      "\n",
      "logreg   0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      1276\n",
      "           1       0.16      0.21      0.18       155\n",
      "\n",
      "    accuracy                           0.80      1431\n",
      "   macro avg       0.53      0.54      0.53      1431\n",
      "weighted avg       0.82      0.80      0.81      1431\n",
      "\n",
      "\n",
      "logreg   0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      1276\n",
      "           1       0.15      0.19      0.17       155\n",
      "\n",
      "    accuracy                           0.80      1431\n",
      "   macro avg       0.53      0.53      0.53      1431\n",
      "weighted avg       0.82      0.80      0.81      1431\n",
      "\n",
      "\n",
      "logreg   0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88      1276\n",
      "           1       0.16      0.22      0.19       155\n",
      "\n",
      "    accuracy                           0.79      1431\n",
      "   macro avg       0.53      0.54      0.53      1431\n",
      "weighted avg       0.82      0.79      0.81      1431\n",
      "\n",
      "\n",
      "logreg   0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88      1276\n",
      "           1       0.15      0.21      0.17       155\n",
      "\n",
      "    accuracy                           0.79      1431\n",
      "   macro avg       0.53      0.53      0.53      1431\n",
      "weighted avg       0.82      0.79      0.80      1431\n",
      "\n",
      "\n",
      "rf       0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      1276\n",
      "           1       0.18      0.17      0.18       155\n",
      "\n",
      "    accuracy                           0.83      1431\n",
      "   macro avg       0.54      0.54      0.54      1431\n",
      "weighted avg       0.82      0.83      0.82      1431\n",
      "\n",
      "\n",
      "rf       0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      1276\n",
      "           1       0.27      0.10      0.15       155\n",
      "\n",
      "    accuracy                           0.87      1431\n",
      "   macro avg       0.58      0.53      0.54      1431\n",
      "weighted avg       0.83      0.87      0.85      1431\n",
      "\n",
      "\n",
      "rf       0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      1276\n",
      "           1       0.29      0.07      0.11       155\n",
      "\n",
      "    accuracy                           0.88      1431\n",
      "   macro avg       0.59      0.52      0.52      1431\n",
      "weighted avg       0.83      0.88      0.85      1431\n",
      "\n",
      "\n",
      "rf       0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      1276\n",
      "           1       0.36      0.03      0.06       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.63      0.51      0.50      1431\n",
      "weighted avg       0.84      0.89      0.85      1431\n",
      "\n",
      "\n",
      "rf       0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1276\n",
      "           1       0.50      0.03      0.06       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.70      0.51      0.50      1431\n",
      "weighted avg       0.85      0.89      0.85      1431\n",
      "\n",
      "\n",
      "rf       0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1276\n",
      "           1       0.25      0.01      0.01       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.57      0.50      0.48      1431\n",
      "weighted avg       0.82      0.89      0.84      1431\n",
      "\n",
      "\n",
      "rf       0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1276\n",
      "           1       0.25      0.01      0.01       155\n",
      "\n",
      "    accuracy                           0.89      1431\n",
      "   macro avg       0.57      0.50      0.48      1431\n",
      "weighted avg       0.82      0.89      0.84      1431\n",
      "\n",
      "\n",
      "gnb      0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.66      0.77      1276\n",
      "           1       0.17      0.56      0.26       155\n",
      "\n",
      "    accuracy                           0.65      1431\n",
      "   macro avg       0.55      0.61      0.51      1431\n",
      "weighted avg       0.84      0.65      0.71      1431\n",
      "\n",
      "\n",
      "gnb      0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.30      0.45      1276\n",
      "           1       0.11      0.75      0.20       155\n",
      "\n",
      "    accuracy                           0.35      1431\n",
      "   macro avg       0.51      0.52      0.32      1431\n",
      "weighted avg       0.82      0.35      0.42      1431\n",
      "\n",
      "\n",
      "gnb      0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.30      0.45      1276\n",
      "           1       0.11      0.72      0.19       155\n",
      "\n",
      "    accuracy                           0.35      1431\n",
      "   macro avg       0.50      0.51      0.32      1431\n",
      "weighted avg       0.81      0.35      0.42      1431\n",
      "\n",
      "\n",
      "gnb      0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.47      0.62      1276\n",
      "           1       0.13      0.63      0.21       155\n",
      "\n",
      "    accuracy                           0.49      1431\n",
      "   macro avg       0.52      0.55      0.41      1431\n",
      "weighted avg       0.83      0.49      0.57      1431\n",
      "\n",
      "\n",
      "gnb      0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.32      0.47      1276\n",
      "           1       0.11      0.71      0.19       155\n",
      "\n",
      "    accuracy                           0.36      1431\n",
      "   macro avg       0.51      0.51      0.33      1431\n",
      "weighted avg       0.81      0.36      0.44      1431\n",
      "\n",
      "\n",
      "gnb      0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.34      0.50      1276\n",
      "           1       0.12      0.72      0.20       155\n",
      "\n",
      "    accuracy                           0.38      1431\n",
      "   macro avg       0.51      0.53      0.35      1431\n",
      "weighted avg       0.82      0.38      0.46      1431\n",
      "\n",
      "\n",
      "gnb      0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.34      0.49      1276\n",
      "           1       0.12      0.72      0.20       155\n",
      "\n",
      "    accuracy                           0.38      1431\n",
      "   macro avg       0.51      0.53      0.35      1431\n",
      "weighted avg       0.82      0.38      0.46      1431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_list2)):\n",
    "    name = models[int(i/len(strat_lst2))][0]\n",
    "    oversamp = strat_lst2[i%7][0]\n",
    "    \n",
    "    print(\"\\n{:<9}{:<.2}\".format(name,oversamp))\n",
    "    print(classification_report(yw2v_test, pred_list2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like it's:\n",
    "## tfidf\n",
    "## logistic regression\n",
    "## oversample to ratio 0.4-0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
